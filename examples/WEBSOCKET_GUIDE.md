# Ejemplos y Pruebas - VisionAI Backend

Esta carpeta contiene **ejemplos de clientes y archivos de prueba** para interactuar con el servidor VisionAI Backend.

> **IMPORTANTE:** Estos archivos son **SOLO PARA PRUEBAS Y DEMOSTRACIÃ“N**. NO son parte de la arquitectura del backend, son ejemplos para que sepas cÃ³mo conectarte desde tu frontend o aplicaciÃ³n cliente.

---

## Archivos en esta Carpeta

| Archivo | DescripciÃ³n |
|---------|-------------|
| `websocket_client_example.py` | Cliente Python CLI para probar WebSocket |
| `test_websocket.html` | Interfaz web de prueba para WebSocket |
| `README.md` | Este archivo (documentaciÃ³n de ejemplos) |

---

## Inicio RÃ¡pido

### 1. Iniciar el Servidor

```bash
# Activar entorno virtual
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Desde la raÃ­z del proyecto
python -m app.main
```

El servidor estarÃ¡ disponible en: **`ws://localhost:8000`**

### 2. Probar con Cliente Python

```bash
# Predecir una imagen
python examples/websocket_client_example.py imagen.jpg

# Procesar carpeta completa
python examples/websocket_client_example.py --folder ./imagenes/

# Listar emociones disponibles
python examples/websocket_client_example.py --emotions

# InformaciÃ³n del modelo ML
python examples/websocket_client_example.py --model-info

# Health check del servidor
python examples/websocket_client_example.py --health
```

### 3. Probar con Interfaz Web

Abre `test_websocket.html` en tu navegador y conecta a `ws://localhost:8000`.

---

## Protocolo WebSocket

### ConexiÃ³n

```javascript
const ws = new WebSocket('ws://localhost:8000');
```

Al conectar, recibes un mensaje de bienvenida:

```json
{
  "type": "welcome",
  "message": "Bienvenido a VisionAI WebSocket Server",
  "version": "2.0.0",
  "commands": {
    "predict": "Predecir emociÃ³n",
    "emotions": "Obtener lista de emociones",
    "model_info": "InformaciÃ³n del modelo ML",
    "health": "Estado del servidor"
  }
}
```

### Comandos Disponibles

#### PREDICT - Predecir EmociÃ³n

**Enviar:**
```json
{
  "command": "predict",
  "image": "iVBORw0KGgoAAAANSUhEUgAA..."
}
```

**Recibir:**
```json
{
  "type": "prediction",
  "status": "success",
  "emotion_name": "happy",
  "confidence": 0.9234,
  "model_version_tag": "v1.0.0",
  "processing_time_ms": 145,
  "timestamp": "2025-11-24T10:30:45.123456"
}
```

#### EMOTIONS - Lista de Emociones

**Enviar:**
```json
{
  "command": "emotions"
}
```

**Recibir:**
```json
{
  "type": "emotions",
  "status": "success",
  "emotions": [
    {"id": 1, "name": "angry", "description": "Enojo o ira"},
    {"id": 2, "name": "disgust", "description": "Disgusto"},
    {"id": 3, "name": "fear", "description": "Miedo"},
    {"id": 4, "name": "happy", "description": "Felicidad o alegrÃ­a"},
    {"id": 5, "name": "neutral", "description": "Neutral"},
    {"id": 6, "name": "sad", "description": "Tristeza"},
    {"id": 7, "name": "surprise", "description": "Sorpresa"}
  ]
}
```

#### MODEL_INFO - InformaciÃ³n del Modelo

**Enviar:**
```json
{
  "command": "model_info"
}
```

**Recibir:**
```json
{
  "type": "model_info",
  "status": "success",
  "info": {
    "status": "loaded",
    "input_shape": [96, 96, 3],
    "num_classes": 7
  }
}
```

#### HEALTH - Estado del Servidor

**Enviar:**
```json
{
  "command": "health"
}
```

**Recibir:**
```json
{
  "type": "health",
  "status": "healthy",
  "service": "VisionAI Backend",
  "timestamp": "2025-11-24T10:30:45",
  "clients_connected": 3
}
```

---

## Ejemplos de CÃ³digo

### Python

```python
import asyncio
import websockets
import json
import base64

async def predict_emotion(image_path):
    uri = "ws://localhost:8000"
    
    async with websockets.connect(uri) as websocket:
        # Recibir bienvenida
        welcome = await websocket.recv()
        print(json.loads(welcome)["message"])
        
        # Leer y codificar imagen
        with open(image_path, "rb") as f:
            image_base64 = base64.b64encode(f.read()).decode()
        
        # Enviar comando de predicciÃ³n
        await websocket.send(json.dumps({
            "command": "predict",
            "image": image_base64
        }))
        
        # Recibir resultado
        response = await websocket.recv()
        result = json.loads(response)
        
        print(f"EmociÃ³n detectada: {result['emotion_name']}")
        print(f"Confianza: {result['confidence']:.2%}")
        print(f"Tiempo de procesamiento: {result['processing_time_ms']}ms")

# Ejecutar
asyncio.run(predict_emotion("rostro.jpg"))
```

### JavaScript/HTML

```html
<!DOCTYPE html>
<html>
<head>
    <title>VisionAI Test</title>
</head>
<body>
    <h1>PredicciÃ³n de Emociones</h1>
    <input type="file" id="imageInput" accept="image/*">
    <button onclick="predict()">Predecir</button>
    <div id="result"></div>
    
    <script>
        let ws = new WebSocket('ws://localhost:8000');
        
        ws.onopen = () => console.log('Conectado a VisionAI');
        
        ws.onmessage = (event) => {
            const msg = JSON.parse(event.data);
            
            if (msg.type === 'prediction') {
                document.getElementById('result').innerHTML = `
                    <h2>Resultado</h2>
                    <p><strong>EmociÃ³n:</strong> ${msg.emotion_name}</p>
                    <p><strong>Confianza:</strong> ${(msg.confidence * 100).toFixed(2)}%</p>
                    <p><strong>Tiempo:</strong> ${msg.processing_time_ms}ms</p>
                `;
            }
        };
        
        async function predict() {
            const file = document.getElementById('imageInput').files[0];
            if (!file) return alert('Selecciona una imagen');
            
            const reader = new FileReader();
            reader.onload = () => {
                const base64 = reader.result.split(',')[1];
                ws.send(JSON.stringify({
                    command: 'predict',
                    image: base64
                }));
            };
            reader.readAsDataURL(file);
        }
    </script>
</body>
</html>
```

---

## ğŸ—ï¸ Arquitectura

```
visionai_backend/
â”œâ”€â”€ app/                          â† BACKEND (servidor)
â”‚   â”œâ”€â”€ main.py                  â† Punto de entrada del servidor
â”‚   â”œâ”€â”€ api/                     â† Rutas y endpoints
â”‚   â”œâ”€â”€ config/                  â† ConfiguraciÃ³n y base de datos
â”‚   â”œâ”€â”€ models/                  â† Modelos SQLAlchemy y schemas
â”‚   â”œâ”€â”€ services/                â† LÃ³gica de negocio
â”‚   â””â”€â”€ utils/                   â† Utilidades
â”‚
â”œâ”€â”€ examples/                     â† EJEMPLOS (este directorio)
â”‚   â”œâ”€â”€ websocket_client_example.py
â”‚   â”œâ”€â”€ test_websocket.html
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ml_models/                    â† Modelos de Machine Learning
â”‚   â””â”€â”€ modelo_emociones.keras
â”‚
â””â”€â”€ requirements.txt
```

### Flujo de Datos

```
Cliente â†’ WebSocket â†’ handle_client()
                          â†“
                    [Router de Comandos]
                          â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                â†“                â†“
    predict()      get_emotions()   model_info()
         â†“                â†“                â†“
  prediction_service   Database      ml_service
         â†“
    [ML Model]
         â†“
    Response â†’ Cliente
```

---

## Casos de Uso

### Ideal para:
- Stream de video en tiempo real
- AnÃ¡lisis continuo de cÃ¡mara web
- Dashboards en vivo
- Aplicaciones mÃ³viles
- IoT y edge computing
- Chat bots con anÃ¡lisis de emociones

### No recomendado para:
- APIs REST pÃºblicas tradicionales
- Integraciones con servicios de terceros sin WebSocket
- Webhooks
- Servicios completamente sin estado

---

## SoluciÃ³n de Problemas

### Error: "Connection refused"
```bash
# Verifica que el servidor estÃ© corriendo
python -m app.main

# Confirma que el puerto 8000 estÃ© libre
netstat -ano | findstr :8000  # Windows
lsof -i :8000                 # Linux/Mac

# AsegÃºrate de usar ws:// no http://
```

### Error: "No module named 'websockets'"
```bash
# Instalar dependencias
pip install -r requirements.txt
```

### Error: "Invalid base64"
- AsegÃºrate de enviar **solo la cadena base64**
- **No incluyas** el prefijo `data:image/png;base64,`
- Verifica que la imagen estÃ© en formato JPEG o PNG

### Servidor no responde
- Revisa los logs del servidor en la terminal
- Verifica la conexiÃ³n a la base de datos PostgreSQL
- Confirma que el modelo ML estÃ© cargado correctamente

### Error en predicciÃ³n
- Verifica formato de imagen (JPEG, PNG)
- Confirma codificaciÃ³n base64 correcta
- Revisa tamaÃ±o de imagen (<5MB recomendado)

---

## Rendimiento

| MÃ©trica | Valor |
|---------|-------|
| **Latencia promedio** | <10ms |
| **Throughput** | 100+ predicciones/segundo |
| **Memoria en uso** | ~500MB (con modelo cargado) |
| **Conexiones simultÃ¡neas** | Hasta 1000 clientes |

---

## Seguridad

Para **producciÃ³n**, implementa:

- Usar **WSS** (WebSocket Secure) en lugar de WS
- Implementar **autenticaciÃ³n JWT**
- Validar **origen de conexiones** (CORS)
- Limitar **tamaÃ±o de imÃ¡genes** (<5MB)
- **Rate limiting** por cliente
- SanitizaciÃ³n de **inputs**
- Logs de **auditorÃ­a**

---

## Recursos Adicionales

- [DocumentaciÃ³n WebSocket](https://websockets.readthedocs.io/)
- [WebSocket API MDN](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [RFC 6455 - WebSocket Protocol](https://tools.ietf.org/html/rfc6455)
- [TensorFlow/Keras Docs](https://www.tensorflow.org/api_docs)

---

## MigraciÃ³n desde FastAPI

Si vienes de una versiÃ³n anterior con FastAPI:

| Antes (FastAPI) | Ahora (WebSocket Puro) |
|----------------|------------------------|
| `uvicorn app.main:app` | `python -m app.main` |
| `http://localhost:8000` | `ws://localhost:8000` |
| POST /api/v1/predict | `{"command": "predict"}` |
| multipart/form-data | JSON + base64 |
| Sin estado persistente | ConexiÃ³n persistente |

---

## Ventajas del WebSocket Puro

| CaracterÃ­stica | WebSocket Puro | FastAPI+REST |
|---------------|----------------|--------------|
| **Overhead** | MÃ­nimo | Alto (HTTP headers) |
| **Latencia** | <10ms | ~50ms |
| **Conexiones** | Persistentes | Por request |
| **Memoria** | Baja | Media-Alta |
| **Escalabilidad** | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜… |
| **Complejidad** | Baja | Media |
| **Bidireccional** | Nativo | Requiere polling |

---

## Licencia

MIT License

## Autores

VisionAI Team